We thank the reviewers for their support and careful reading, and we will correct the minor points not addressed below.

Reviewer A

> The extension is a little ad hoc.

This seems unfair, given the relation between $\text{CP}_{\text{ND}}$ and bounded linear logic.
$\text{CP}_{\text{ND}}$ has exact indices instead of upper bounds, making it linear instead of affine, and uses pooling instead of storage—allowing the processes under a $!_n$ to have different computational content—but storage is admissible in $\text{CP}_{\text{ND}}$.

> Theorem 3 and 7: This is a rather weak property; because of the definition of canonical forms, it sound almost like a tautology. Note that according to Definition 11, deadlocked processes like $(\nu x)(x().y[] | y().x[])$ is in canonical form.

The example deadlocked process mentioned by the reviewer may be in canonical form, but it is not well-typed. For CP, the soon-to-be deadlocked process $a().(\nu x)(x().y[] | y().x[])$ is also in canonical form, and also not well-typed.

Reviewer B

> In my color printout, the red and blue colors of the text look a bit washed out and so there isn't quite enough contrast.

If the problem is with the reviewer's printer then we request it not be held against us.

> What does "nodcap" mean?

It is simply the pronunciation we use for $\text{CP}_{\text{ND}}$.

> Can n be 0?

In the presented system, n cannot be 0, as we are only allowed singletons and CONT/POOL. It is possible to extend the system with weakening, which would allow you to construct the 0-case. However, we found that this does not type interesting processes.

Reviewer C

> ...the absence of a natural rule to account for a single server to split into two independent ones...

A server is a series of possibly dependent interactions. We can only split a server into two independent ones if internally its interactions were already independent. Therefore, it is not possible to derive a general rule for this.

However, if we already have two independent servers, then we can split a client pool and divide them over the two servers, effectively implementing a load balancer of sorts. This is a process typed by $\vdash x : !_{pn}A, y : ?_p(?_n A^{\bot})$, i.e. it takes $pn$ clients, and distributes them over $p$ servers taking $n$ clients each. (Or $\vdash x : !_{\Sigma k_i} A, y_1 : ?_{k_1} A^{\bot}, ..., y_n : ?_{k_n} A^{\bot}$ for the general case.)

From the point of view of the logic, a server acts as a series of parrs. If we want to split a server, this is splitting a series of parrs into two series of parrs joined by a tensor. Therefore, it would require adding the axiom that allows us to turn a parr into a tensor, which is equivalent to adding multicut, and which lets deadlocks back in.

Reviewer D

> ...a seemingly simple variation over an existing system...

It took us a year to develop this system and to simplify the proofs. The connection to BLL was not at all obvious to us when we began; it was spotted by Garrett halfway through the work—up to that point, Phil had thought this line of work was unpromising. It may seem simple in retrospect, but it was not simple in prospect.

> ...more examples would be more compelling...

Every race we can think of—selling the last ticket to a concert, selling the last copy of a book on Amazon, or allocating a bounded resource—has a similar structure to the cake problem. Writing out the same structure multiple times did not seem helpful. What kind of examples would the reviewer like to see?

> ...presentation suggestion...

Thank you, we will incorporate it.
