\documentclass[10pt,a4paper,twocolumn,notitlepage]{article}
\input{preamble}
\usepackage[margin=0.75in]{geometry}

\title{Give or take \\
  {\large Non-Determinism, Linear Logic and Session Types}}
\author{Wen Kokke \\
  CDT Pervasive Parallelism \\
  \url{pepijn.kokke@ed.ac.uk}}

\begin{document}
\maketitle

\begin{abstract}
  The aim of this project is to extend the session-typed \textpi-calculus CP
  \citep{wadler2012} with \emph{global} non-determinism---i.e.\ without using an
  explicit program construct for non-determinism---while preserving the strong
  guarantees of termination and deadlock freedom that are offered by the
  correspondence with classical linear logic. 
  
  Our extended version of CP will allow us to model more complex concurrent
  processes, such as an online ticket vendor which can sell some finite number
  of tickets, with customers racing to obtain a ticket.
  %
  We will be able to model further complications, such as a ticket vendor for
  which all tickets are distinct---e.g.\ by being labeled with distinct serial
  numbers---and vendors who maintain a list detailing which customer bought
  which ticket.
  %
  All of these are open problems for logic-inspired session-typed systems which
  guarantee termination.
\end{abstract}

\section{Introduction}
%\outline{I will briefly introduce the problem---logic-inspired session-typed
%  systems do not model non-deterministic processes. We would like to have
%  non-determinism, but we don't want non-termination or deadlocks.}
Curry-Howard correspondences are a powerful tool in the design of programming
languages. Once such a correspondence between a programming language and a
logical system is established, we can leverage any property of the logic system
as a property of the programming language---and vice versa. One such property is
termination. In logic, it is crucial that cut elimination---which corresponds to
\emph{computation}---terminates. We can leverage this property to state that all
our programs terminate.

In practice, strong properties such as termination tend to be both a blessing
and a curse. We know that our programs will never enter an infinite loop---a
blessing, as such bugs are arguably difficult to debug. However, it also
restricts one of the programmers most powerful tools---general recursion.
There are many restricted forms of recursion which are known to
terminate. Examples are primitive recursive functions, structural
recursion~\citep{burstall1969}, Walther recursion~\citep{walther1994}, and sized
types~\citep{lee2001}. Whether programming in a total function language is
feasible depends largely on whether the form of recursion is sufficiently
natural to programmers.
However, if we do not have such a restricted form of recursion, and a proof that
it terminates, then we are nowhere.

The \textpi-calculus~\citep{milner1992a,milner1992b} is a process calculus---a formal system
which models concurrent computation.
It is arguably as foundational as the \textlambda-calculus, in the sense that it
is equally bare bones: it does not come equipped with any notions of data types
or values, but consists solely of communication channels and processes.
A Curry-Howard correspondence between a variant of the \textpi-calculus and
linear logic has only recently been discovered~\citep{caires2010,wadler2012}.
In these two systems, there is a tight correspondence between the typing rules
and the inference rules of intuitionistic and classical linear logic,
respectively, and between computation (or communication) and cut elimination.
It is the latter, once again, which turns out to be both a curse and a blessing.

One property which cut elimination tends to have is determinism---if we apply
cut elimination to the same proof, we always get the same result. 
However, in the context of concurrent computation this is \emph{not} what we
want. We may want to model non-deterministic computations---e.g.\ races.
One example of such a race, which we will use throughout this text, is a
p\^{a}tisserie. Imagine a p\^{a}tisserie which only has \emph{one} cake left in
store. Now imagine two customers, leaving their houses to go any buy a cake at
exactly the same time. Who will end up with a cake, and who will get a plate of
disappointment? This depends entirely on outside conditions---who lives closer,
who gets struck in traffic, etc---and, importantly, it does not depend on either
customer or the p\^{a}tisserie.

In this text we will propose an extension of CP~\citep{wadler2012} which is
capable of modeling such interactions without losing the strong properties which
the correspondence with classical linear logic gives us. A consequence of this
is that we will have to make cut elimination non-deterministic.
In what follows, we will describe how we will extend classical linear logic,
based on the work on bounded linear logic~\citep[BLL;][]{girard1992}, to allow
for some margin of non-determinism. 

\section{Background}
Before we delve into our proposed solution, it would be wise to briefly discuss
related work. In the following sections, we will briefly touch on the syntax and
semantics of the \textpi-calculus, the session-typing paradigm, which has led to
a correspondence between a typed \textpi-calculus and linear logic, current
solutions to non-determinism in such \textpi-calculi, and bounded linear logic.

\subsection{The \textpi-calculus}
The \textpi-calculus is a process calculus, introduced by \citet{milner1992a,milner1992b}.
It models processes communicating on named channels. The terms of the
\textpi-calculus are defined as follows, over an infinite set of names which we
denote by lowercase letters.
\begin{align*}
  S, P, &\; Q, R \;\coloneqq \\
        & \nu x.P        &&\text{create new channel x, then run P}\\
        & x[y].P         &&\text{send y on channel x, then run P}\\
        & x(y).P         &&\text{receive y on channel x, then run P}\\  
        & P \mid Q       &&\text{run P and Q in parallel}\\
        & 0              &&\text{halt}
\end{align*}
Formally, the reduction of \textpi-calculus terms is defined using a structural
congruence, which itself is defined as an extension over renaming.
\begin{gather*}
  P \mid 0 \equiv P \quad
  P \mid Q \equiv Q \mid P \quad 
  (P \mid Q) \mid R \equiv P \mid (Q \mid R) \\
  (\nu x)(\nu y)P \equiv (\nu y)(\nu x)P \quad
  (\nu x)0 \equiv 0 \\
  (\nu x)(P \mid Q) \equiv (\nu x)P \mid Q \quad \text{($x$ is not free in $Q$)}
\end{gather*}
These equivalences state that parallel composition is commutative and
associative, and has the inactive process as its unit; that the order of
channel creation does not matter; that creating a channel for the inactive
process is pointless; and that it is harmless to extend the scope of a channel
to include $Q$ if the channel is not used in $Q$. Reduction is then defined
with the following rule
\[
  x[z].P \mid x(y).Q \longrightarrow P \mid \subst{Q}{z}{y}
  \quad
  \text{(communication)}
\]
Together with three other rules which state that we can perform communication
under parallel composition and name restriction, and that we can rewrite by
structural congruence.

The terms discussed so far would be sufficient for a discussion of the
\textpi-calculus. However, \citet{wadler2012} uses some non-standard constructs
in his formulation of CP. With the next section in mind, we discuss these
extensions as well.
 
There are three main groups of extensions.
The first of these is the link construct, $\link{x}{y}$, which forwards messages
from x to y, or vice versa, depending on the direction of information flow.
The second is binary choice. Such a choice involves two processes---one offering
a choice, and one making it. 
\begin{align*}
  & \inl{x}{P}     &&\text{choose left on x, then run P}\\
  & \inr{x}{P}     &&\text{choose right on x, then run P}\\
  & \case{x}{P}{Q} &&\text{receive choice on X, then run P or Q}\\
\end{align*}
Lastly, \citet{wadler2012} uses empty versions of communication and choice.
These will be used as the interpretations of the unit types of linear logic. 
Empty communication corresponds to sending a ping and halting, or receiving a
ping. 
\begin{align*}
  & x[].0          &&\text{send ping on x, then halt}\\
  & x().P          &&\text{wait for ping on x, then run P}\\
  \intertext{
  Empty choice will be a nullary choice. Since there are no options in a nullary
  choice, we will have no construct to send one. The empty case construct, which
  offers a nullary choice, will consequently have to wait forever.
  }%
  & \case{x}{\:}{}   &&\text{empty choice}
\end{align*}

\subsection{Session Types and Linear Logic}
Linear logic was discovered by \citeauthor{girard1987}, in \citeyear{girard1987},
as a generalization of classical and intuitionistic logic, and from the
beginning it held great promise for computer science.
Limiting the unbounded reuse of propositions, it is a logic of resources and
usages. Therefore, it could---and has since---be used to describe programming
languages which regulate access to memory. Furthermore, it has always held the
promise of being a logic of communication. Both of these are made apparent in
the language which \citet{girard1987} uses to describe his logic. When he speaks
about the exponentials, he speaks about storage and registers. Yet he names one
of the operators par ($\parr$), and talks about programs asking questions and
giving answers.

\citet{honda1993}, inspired by linear logic, developed session types.
While his session-typed functional programming language is linear, and it uses
two of linear logic's connectives, there is no direct correspondence.
In fact, it is not until \citeyear{caires2010} that \citeauthor{caires2010}
establish a tight correspondence between the \textpi-calculus and intuitionistic
linear logic.

Two years later, \citet{wadler2012} establishes a similar correspondence between
the \textpi-calculus and classical linear logic. He calls the resulting system
CP. In the same paper, he ties this work in with the branch of research on
session-typed functional languages, spawned by \citet{honda1993}, using a
variant of the language developed by \citet{gay2009}, which he calls GV.

In this text we will focus on CP, as we believe that a process calculus and a
classical type system are the right language to describe communication.
In~\autoref{fig:cp}, we show the typing rules for the rudimentary fragment of
CP---that is, the fragment without unbounded communication or polymorphism.
This leaves us with the four binary connectives---tensor, par, plus and
with---and their units---one, bottom, zero and top, respectively.

As described above, CP has a tight correspondence with linear logic. One
consequence of this is that communication is identified with cut elimination.
The problem with this tight correspondence is that communication is
deterministic.
\begin{figure*}
  \centering
  \[
    \text{Type}\; A , B \coloneqq A \mid A^\bot
                             \mid 1 \mid A \mult B \mid \bot \mid A \parr B
                             \mid 0 \mid A \plus B \mid \top \mid A \with B
  \]
  \begin{proofbox}
    \AXC{}
    \NOM{Ax}
    \UIC{$\seq[ \link{x}{y} ]{ \tm[x]{A} , \tm[y]{A^\bot} }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{$\seq[ P ]{ \Gamma , \tm[x]{A} }$}
    \AXC{$\seq[ Q ]{ \Delta , \tm[x]{A^\bot} }$}
    \NOM{Cut}
    \BIC{$\seq[ \nu x.(P \mid Q) ]{ \Gamma , \Delta }$}
  \end{proofbox}
  \\[1\baselineskip]
  \begin{proofbox}
    \AXC{$\seq[ P ]{ \Gamma , \tm[y]{A} }$}
    \AXC{$\seq[ Q ]{ \Delta , \tm[x]{B} }$}
    \SYM{\mult}
    \BIC{$\seq[{ x[y].(P \mid Q) }]{
        \Gamma , \Delta , \tm[x]{A \mult B} }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{$\seq[ P ]{ \Gamma , \tm[y]{A} , \tm{x}{B} }$}
    \SYM{\parr}
    \UIC{$\seq[ x(y).P ]{ \Gamma , \tm[x]{A \parr B} }$}
  \end{proofbox}
  \\[1\baselineskip]
  \begin{proofbox}
    \AXC{$\seq[ P ]{ \Gamma , \tm[x]{A} }$}
    \SYM{\plus_1}
    \UIC{$\seq[{ \inl{x}{P} }]{ \Gamma , \tm[x]{A \plus B} }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{$\seq[ P ]{ \Gamma , \tm[x]{B} }$}
    \SYM{\plus_2}
    \UIC{$\seq[{ \inr{x}{P} }]{ \Gamma , \tm[x]{A \plus B} }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{$\seq[ P ]{ \Gamma , \tm[x]{A} }$}
    \AXC{$\seq[ Q ]{ \Delta , \tm[x]{B} }$}
    \SYM{\with}
    \BIC{$\seq[ \case{x}{P}{Q} ]{ \Gamma , \Delta }$}
  \end{proofbox}
  \\[1\baselineskip]
  \begin{proofbox}
    \AXC{}
    \SYM{1}
    \UIC{$\seq[{ x[].0 }]{ \tm[x]{1} }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{$\seq[P]{ \Gamma }$}
    \SYM{\bot}
    \UIC{$\seq[{x().P}]{ \Gamma , \tm[x]{\bot} }$}
  \end{proofbox}
  (no rule for 0)
  \begin{proofbox}
    \AXC{}
    \SYM{\top}
    \UIC{$\seq[ \case{x}{}{} ]{ \tm[x]{\top} }$}
  \end{proofbox}
  \caption{Typing rules for rudimentary CP.}\label{fig:cp}
\end{figure*}

\subsection{Linearity and Non-Determinism}
There are several existing approaches which add non-determinism to linear
typed process calculi. However, all of these approaches are centered around a
shared idea: local choice. Let us take the work by \citet{atkey2016} as an
example. They add two new typing rules.
\begin{center}
  \begin{proofbox}
    \AXC{$\seq[P]{ \Gamma }$}
    \AXC{$\seq[Q]{ \Gamma }$}
    \BIC{$\seq[P+Q]{ \Gamma }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{}
    \UIC{$\seq[\text{fail}]{ \Gamma }$}
  \end{proofbox}
\end{center}
The first rule is local choice: it joins two processes $P$ and $Q$ of the same
type, and when run will non-deterministically choose to run one of them.
\begin{gather*}
  P+Q \longrightarrow P \\
  P+Q \longrightarrow Q
\end{gather*}
The second rule models failure---an optional unit for local choice.
From the perspective of logic, the inclusion of failure has obvious negative
consequences. Indeed, \citet{atkey2016} show that in the presence of local
choice and failure, we get proofs of $\top \lequiv 0$ and $A \with B \lequiv A
\plus B$.

\citet{caires2014,caires2017} use a similar approach. The difference in their
work is that they embed local choice and failure in a monad, represented by the
exponentials ${\with}A$ and ${\plus}A$.
\begin{center}
  \begin{proofbox}
    \AXC{$\seq[P]{ \Gamma , \tm[x]{A} }$}
    \UIC{$\seq[{x[\text{some}].P}]{ \Gamma , \tm[x]{{\with}A} }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{$\seq[P]{ {\with}\Gamma , \tm[x]{A} }$}
    \UIC{$\seq[{x(\text{some}).P}]{ {\with}\Gamma , \tm[x]{{\plus}A} }$}
  \end{proofbox}
  \\[1\baselineskip]
  \begin{proofbox}
    \AXC{$\seq[P]{ {\with}\Gamma }$}
    \AXC{$\seq[Q]{ {\with}\Gamma }$}
    \BIC{$\seq[P+Q]{ {\with}\Gamma }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{}
    \UIC{$\seq[{x[\text{none}].0}]{ \tm[x]{{\with}A} }$}
  \end{proofbox}
\end{center}
The first two rules setup a pair of exponentials, and the latter two correspond
to local choice and failure.

Why do we want to avoid local choice? Let us go back to our example.
Recall that we would like to model a p\^{a}tisserie which has one remaining
cake, and two customers racing in order to purchase it.
We \emph{can} encode this example using local choice.
We write the program for the p\^{a}tisseur as the local choice between
\begin{gather*}
  x[\text{cake}].y[\text{disappointment}].0 \\
  + \\
  y[\text{cake}].x[\text{disappointment}].0
\end{gather*}
where $x$ and $y$ are the communication channels with the two customers. 

However, this does not model our race.
This models the scenario where our p\^{a}tiseur decides which customer
gets to purchase the cake on a whim, and then waits for that customer
regardless of whether the other customer has already arrived at the store.
This is not what we intended---and worse, it is \emph{rude}.

As we emphasized earlier, the responsibility for choosing who gets the cake
should not lie with the p\^{a}tiseur, nor should it lie with either customer.

\subsection{Bounded Linear Logic}
Bounded linear logic (BLL) was introduced by~\citeauthor{girard1992} in
\citeyear{girard1992}, with the intention of demonstrating the feasibility of
type systems which guarantee a certain complexity.
Specifically, it is a restricted version of intuitionistic linear logic, in
which all programs have polynomial time complexity.
It achieves this by requiring that the number of memory accesses is bounded by a
polynomial.
This is done by replacing the usual rules for the exponentials with the
following bounded variants (which are presented here \emph{clasically}, in order
to make their subsequent integration into CP easier to follow).
\begin{center}
  \begin{proofbox}
    \AXC{$\seq{ \give[m]{\Gamma} , A }$}
    \NOM{Store}
    \UIC{$\seq{ \give[mn]{\Gamma} , \take[n]{A} }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{$\seq{ \Gamma }$}
    \NOM{Weaken}
    \UIC{$\seq{ \Gamma , \give[0]{A} }$}
  \end{proofbox}
  \\[1\baselineskip]
  \begin{proofbox}
    \AXC{$\seq{ \Gamma , \give[n]{A} , \give[m]{A} }$}
    \NOM{Contract}
    \UIC{$\seq{ \Gamma , \give[n+m]{A} }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{$\seq{ \Gamma , A }$}
    \NOM{Derelict}
    \UIC{$\seq{ \Gamma , \give[1]{A} }$}
  \end{proofbox}
\end{center}
It is clear that \citet{girard1992} use the exponentials to model memory.
In fact, \citet{girard1987} already describes the unbounded exponential
$\take{A}$ in such terms: 
\begin{quote}
  An answer of type $\take{A}$ corresponds to the idea of writing an answer of
  type $A$ in some stable register so that it can be used \emph{ad nauseam}.
\end{quote}
In BLL, the only difference is that when we write a value to a register, we
specify how many times that value will be read, and the type system ensures that
a stored value will be read exactly as many times as we intended.

In the context of session types, $\take{A}$ and $\give{A}$ are traditionally
used to model servers and clients, though their semantics remain unchanged.
This results in servers acting like stable registers---sending out the same
value over and over again.

\section{Methodology}
In this section, we will discuss which changes we will make to CP to be able to
model non-deterministic computation. In addition, we will sketch process
semantics for these constructs.

\subsection{Give and take}\label{sec:give-and-take}
Our aim is to add some construct for global non-determinism to CP.
In the \textpi-calculus, the non-determinism comes from two things: channel
sharing and the structural congruence relation.
This allows you to write a process such as e.g.\ %
\[
  (x[u].x[v].P \mid x(y).Q \mid x(z).R)
\]
This process is non-deterministic, because it is not determined a priori which
value sent along $x$ will be received by which process. 

In CP, however, channels are strictly binary---all communication is introduced
by the \textsc{Cut}-rule, which creates a channel with two endpoints, and hands
each endpoint to \emph{one} process (see~\autoref{fig:cp}).
Furthermore, CP defines its reduction semantics on \emph{typed} processes, and
its structural congruence is weaker than that of the \textpi-calculus.
As a consequence, computation in CP is completely deterministic.
There, we plan to extend CP with types which capture safe name sharing.
We do this by extending CP with a pair of bounded exponentials, modeled on those
of bounded linear logic. These are $\give[n]{A}$ (give) and $\take[n]{A}$
(take), where $n \in \mathbb{N}$. 
We refer to the resulting system as \gtcp.

Our interpretation of $\give[n]{A}$ remains close to BLL---it represents a
process which communicates as $A$, $n$ times.
We depart from BLL, however, with our interpretation of $\take[n]{A}$.
Instead of interpreting $\take[n]{A}$ as a stable register, which gives out the
same value $n$ times, we take $\take[n]{A}$ to model a \emph{pool} of $n$
independent processes, each of which communicates as $A$ in its own way.
It is this \emph{pooling} of processes which allows for name sharing, and
therefore non-determinism.
\begin{center}
  \begin{proofbox}
    \AXC{$\seq[P]{ \Gamma , \tm[x]{\give[m]{A}} , \tm[x']{\give[n]{A}} }$}
    \NOM{Contract}
    \UIC{$\seq[\subst{P}{x}{x'}]{ \Gamma , \tm[x]{\give[m+n]{A}} }$}
  \end{proofbox}
  \\[1\baselineskip]
  \begin{proofbox}
    \AXC{$\seq[P]{ \give[n]{\Gamma} , \tm[y]{A} }$}
    \SYM{\take[1]{}}
    \UIC{$\seq[{x(y).P}]{ \give[n]{\Gamma} , \tm[x]{\take[1]{A}} }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{$\seq[{P}]{ \Gamma , \tm[y]{A} }$}
    \SYM{\give{}}
    \UIC{$\seq[{x[y].P}]{ \Gamma , \tm[x]{\give[1]{A}} }$}
  \end{proofbox}
  \\[1\baselineskip]
  \begin{proofbox}
    \AXC{$\seq[P]{ \Gamma , \tm[x]{\take[m]{A}} }$}
    \AXC{$\seq[Q]{ \Delta , \tm[x]{\take[n]{A}} }$}
    \NOM{Pool}
    \BIC{$\seq[P \mid Q]{ \Gamma , \Delta , \tm[x]{\take[m+n]{A}} }$}
  \end{proofbox}
\end{center}
The trick to non-determinism is in our proposed cut elimination procedure.
When faced with a cut on a channel of type $\give[n]{A^\bot} / \take[n]{A}$, the
cut elimination procedure will pick an arbitrary process from the pool of
processes $\take[n]{A}$ for each successive communication of the process
$\give[n]{A^\bot}$.
Thus, we rewrite such a cut into $n$ smaller cuts. 

An interesting consequence of this is that if the endsequent does not contain
any channels of type $\give[n]{A}$ or $\take[n]{A}$, then we should be able to
eliminate \emph{all} usage of the rules for non-determinism. This is
good---after running a non-deterministic program, we should expect to end up in
some deterministic end state.

\section{Relation to bounded linear logic}
The system \gtcp\ differs in some fundamental ways from BLL.
First and foremost, this is obvious in our chosen model: BLL models programs
with restricted memory access, whereas \gtcp\ models non-deterministic
communicating processes.
Directly related to this is the fact that \gtcp\ is classical, whereas BLL is
intuitionistic.

However, there are some more subtle difference as well.
In some sense, $\take[1]{}$ and \textsc{Pool} are a generalization of
\textsc{Store}.
We can show this by deriving \textsc{Store} for $n \ge 1$.
\begin{proofblock}
  \AXC{IH}
  \noLine
  \UIC{$\vphantom{!}\smash[t]{\vdots}$}
  \noLine
  \UIC{$\seq{ \give[mn]{\Gamma} , \take[mn]{A} }$}
  \AXC{$\rho$}
  \noLine
  \UIC{$\vphantom{!}\smash[t]{\vdots}$}
  \noLine
  \UIC{$\seq{ \give[m]{\Gamma} , \take[m]{A} }$}
  \NOM{Pool}
  \BIC{$\seq{ \give[mn]{\Gamma} , \give[m]{\Gamma} , \take[m(n+1)]{A} }$}
  \NOM{Contract}
  \UIC{$\seq{ \give[m(n+1)]{\Gamma} , \take[m(n+1)]{A} }$}
\end{proofblock}
We emulate a stable register, which can be accessed $n$ times to obtain the
value $\rho$, by pooling together $n$ copies of the process $\rho$. 
The obvious implication of this emulation is that we actually \emph{store} $n$
copies, instead of letting a single copy be accessed $n$ times.

One the other hand, we cannot derive \textsc{Store} for $n = 0$.
We also do not have weakening.
If we wish \gtcp\ to be an extension of BLL, we should add two more rules.
\begin{center}
  \begin{proofbox}
    \AXC{$\seq[P]{ \give[n]{\Gamma} , \tm[y]{A} }$}
    \SYM{\take[0]{}}
    \UIC{$\seq[0]{ \give[0]{\Gamma} , \tm[x]{\take[0]{A}} }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{$\seq[P]{ \Gamma }$}
    \NOM{Weaken}
    \UIC{$\seq[P]{ \Gamma , \tm[x]{\give[0]{A}} }$}
  \end{proofbox}
\end{center}
These rules model \emph{irrelevance}.
This becomes more obvious once we look at the processes associated with
$\take[0]{}$: it checks the type of a process only to throw it out.

We believe that these rules will play no role in the cut elimination of the
\emph{relevant} portion of \gtcp, and therefore choose to leave them out,
restricting the exponentials to the case where $n \ge 1$
However, they may become interesting in more expressive versions of CP, such as
one which adds dependent types~\citep[see][]{mcbride2016}

\subsection{A p\^{a}tisserie and its customers}
We can use the new connectives to implement non-deterministic programs.
We will discuss an example: a p\^{a}tisserie, and its customers.
To keep things simple, we will model a p\^{a}tisserie which has exactly
\emph{one} cake to sell, and we will model the scenario where there are
\emph{two} customers racing to buy that cake.
However, the rules presented in~\autoref{sec:give-and-take} can model such
interactions with an arbitrary number of cakes and an arbitrary number of
customers.

In \autoref{fig:cake-store}, we show two programs involved in our example.
The first process represents a customer. Customers want a channel over which
they either can buy a cake---trading a coin for a cake---or which tells them
when cake is unavailable. This is represented using the type
$(\coin\mult\cake^\bot)\with\bot$.
The second process is the p\^{a}tisserie itself. It offers up a channel of type
$\give[2]{(\coin^\bot\parr\cake)\plus{1}}$---a channel over which two customers
can try to purchase a cake simultaneously.
\begin{figure*}
  \begin{mdframed}
    \vspace*{1em}
    \begin{proofblock}  
      \AXC{$\vphantom{!}\smash[t]{\vdots}$}
      \noLine
      \UIC{$\seq[P]{ \Gamma , \tm[y]{\coin} }$}
      \AXC{$\vphantom{!}\smash[t]{\vdots}$}
      \noLine
      \UIC{$\seq[Q]{ \Delta , \tm[z]{\cake^\bot} }$}
      \BIC{$\seq[{y[z].(P \mid Q)}]{
          \Gamma , \Delta , \tm[y]{\coin\mult\cake^\bot} }$}
      \AXC{$\vphantom{!}\smash[t]{\vdots}$}
      \noLine
      \UIC{$\seq[R]{ \Gamma , \Delta }$}
      \SYM{\bot}
      \UIC{$\seq[{y().R}]{ \Gamma , \Delta , \tm[y]{\bot} }$}
      \SYM{\with}
      \BIC{$\seq[{\case{y}{y[z].(P \mid Q)}{y().R}}]{
          \Gamma , \Delta , \tm[y]{(\coin\mult\cake^\bot) \with \bot} }$}
      \SYM{\take[1]{}}
      \UIC{$\seq[{!x(y).\case{y}{y[z].(P \mid Q)}{y().R}}]{
          \Gamma , \Delta ,
          \tm[x]{\take[1]{((\coin\mult\cake^\bot) \with \bot)}} }$}
    \end{proofblock}
    \vspace*{0pt}
    \begin{proofblock} 
      \AXC{}
      \SYM{1}
      \UIC{$\seq[{y[].0}]{ \tm[y]{1} }$}
      \SYM{\plus_2}
      \UIC{$\seq[{\inr{y}{y[].0}}]{
          \tm[y]{(\coin^\bot\parr\cake)\plus{1}} }$}
      \SYM{\give{}}
      \UIC{$\seq[{?x'[y].\inr{y}{y[].0}}]{
          \tm[x']{\give[1]{((\coin^\bot\parr\cake)\plus{1})}} }$}
      \noLine
      \UIC{$\vphantom{!}\smash[t]{\vdots}$}
      \noLine
      \UIC{$\seq[{\mathcal{E}[{\inr{x'}{x'[].0}}]}]{
          \Theta ,
          \tm[z]{\coin^\bot\parr\cake} ,
          \tm[x']{\give[1]{((\coin^\bot\parr\cake)\plus{1})}} }$}
      \SYM{\plus_1}
      \UIC{$\seq[\inl{z}{\mathcal{E}[{?x'(y).\inr{y}{y[].0}}]}]{
          \Theta ,
          \tm[z]{(\coin^\bot\parr\cake)\plus{1}} ,
          \tm[x']{\give[1]{((\coin^\bot\parr\cake)\plus{1})}} }$}
      \SYM{\give{}}
      \UIC{$\seq[{?x[z].\inl{z}{\mathcal{E}[{?x'[y].\inr{y}{y[].0}}]}}]{
          \Theta ,
          \tm[x]{\give[1]{((\coin^\bot\parr\cake)\plus{1})}} ,
          \tm[x']{\give[1]{((\coin^\bot\parr\cake)\plus{1})}} }$}
      \NOM{Contract}
      \UIC{$\seq[{?x[z].\inl{z}{\mathcal{E}[{?x[y].\inr{y}{y[].0}}]}}]{
          \Theta ,
          \tm[x]{\give[2]{((\coin^\bot\parr\cake)\plus{1})}} }$}
    \end{proofblock}
    \vspace*{0pt}
  \end{mdframed}
  \caption{A p\^{a}tisserie and its customers.}\label{fig:cake-store}
\end{figure*}

To run the program, we pool two customers together, and have them communicate
with the store through cut elimination. Note that the responsibility of choosing
which customer gets the cake does not lie with the p\^{a}tisserie---instead, it
is decided by cut elimination. The cut on
$\tm[x]{\give[n]((\coin^\bot\parr\cake)\plus{1})}$ is replaced by two smaller
cuts on the channels $x$ and $x'$---the two channels that were merged using
\textsc{Contract} (see~\autoref{fig:cake-store}). Both these channels have the same
type, and therefore it is up to the cut elimination procedure to decide which of
these channels is cut together with which client channel.

It may strike the reader as odd to see the p\^{a}tisserie represented using
$\give[n]{A}$ instead of $\take[n]{A}$.
In the literature on linear logic inspired session types, the type $\take{A}$,
and not $\give{A}$, is traditionally taken to represent
servers~\citep{caires2010,wadler2012}.
We argue that this is no mistake on our part.
In both of these works, the term corresponding to the server type $\take{A}$ is
an input---a \emph{blocking} read.
This is perfectly in line with our conception of a web server, which waits for
clients to send it a request.
However, in a p\^{a}tisserie, it is the customer who waits in line until the
p\^{a}tissier has time for them.\footnote{
  This does not take away the feeling that perhaps $\give[n]{A}$ and
  $\take[n]{A}$ are a misnomer, and they should be referred to as
  ${\parr}_{n}{A}$ and ${\mult}_{n}{A}$ instead---see
  \autoref{sec:take-tensors-give-pars}. 
}

\subsection{Take tensors, give pars}\label{sec:take-tensors-give-pars}
The bounded modalities give ($\give[n]{A}$) and take ($\take[n]{A}$) have a
strong connection to par ($\parr$) and tensor ($\mult$)---they are vectors of
pars and tensors.\footnote{
  The exponentials $\give{A}$ and $\take{A}$ have similar relations to par and
  tensor, except that they represent unbounded streams of pars and tensors,
  instead of bounded vectors, and that objects in a $\take{A}$ stream are
  identical.
}
We can demonstrate this showing that we can fold a series of pars into a give.
\begin{proofblock}
  \AXC{}
  \NOM{Ax}
  \UIC{$\seq{ A^\bot , A }$}
  \SYM{\give{}}
  \UIC{$\seq{ A^\bot , \give[1]{A} }$}
  \AXC{IH}
  \noLine
  \UIC{$\vphantom{!}\smash[t]{\vdots}$}
  \noLine
  \UIC{$\seq{ A^\bot \mult \ldots \mult A^\bot , \give[n]{A} }$}
  \SYM{\mult}
  \BIC{$\seq{ A^\bot \mult A^\bot \mult \ldots \mult A^\bot ,
      \give[1]{A} , \give[n]{A} }$}
  \NOM{Contract}
  \UIC{$\seq{ A^\bot \mult A^\bot \mult \ldots \mult A^\bot ,
      \give[n+1]{A} }$}
\end{proofblock}
And vice versa---we can unfold a give into a series of pars.
\begin{proofblock}
  \AXC{}
  \NOM{Ax}
  \UIC{$\seq{ A^\bot , A }$}
  \SYM{\give{}}
  \UIC{$\seq{ A^\bot , \give[1]{A} }$}
  \SYM{\take[1]{}}
  \UIC{$\seq{ \take[1]{A^\bot} , \give[1]{A} }$}
  \AXC{IH}
  \noLine
  \UIC{$\vphantom{!}\smash[t]{\vdots}$}
  \noLine
  \UIC{$\seq{ \take[n]{A^\bot} ,
      \give[1]{A} \parr \ldots \parr \give[1]{A} }$}
  \NOM{Pool}
  \BIC{$\seq{ \take[n+1]{A^\bot} , \give[1]{A} ,
      \give[1]{A} \parr \ldots \parr \give[1]{A} }$}
  \SYM{\parr}
  \UIC{$\seq{ \take[n+1]{A^\bot} ,
      \give[1]{A} \parr \give[1]{A} \parr \ldots \parr \give[1]{A} }$}
\end{proofblock}
This second proof feels a little unsatisfactory, due to the presence of the
$\give[1]{A}$ on the unfolded values. We will discuss this in
\autoref{sec:unit-vectors}.
For now, observe that we can lift all values in the first proof into
$\give[1]{}$, and obtain the following equivalence.
\[
  \give[n]{A} \lequiv \give[1]{A} \parr \ldots \parr \give[1]{A}.
\]
We can give similar proofs for take and tensor. Thus, we also have 
\[
  \take[n]{A} \lequiv \take[1]{A} \mult \ldots \mult \take[1]{A}.
\]
And lastly, if we included empty vector, using $\take[0]{}$ and \textsc{Weaken},
we could extend this correspondence to
\[
  \give[0]{A} \lequiv \bot \quad \text{and} \quad \take[0]{A} \lequiv 1.
\]

\subsection{Conflating $\give[1]{A}$ and $\take[1]{A}$}\label{sec:unit-vectors}
In the previous section, we have demonstrated the strong connection between give
and take, and tensor and par. However, the final equivalences were unsatisfying,
as we could only unfold a value $\give[n]{A}$ to $n$ values of type
$\give[1]{A}$. It would be much more pleasing if we had
\[
  \give[n]{A} \lequiv A \parr \ldots \parr A
  \quad \text{and} \quad
  \take[n]{A} \lequiv A \mult \ldots \mult A.
\]
And we already have one direction of these proofs!
Why not the other?
The reason  lies with the $\take[1]{}$ rule: it requires every value in its
context to be under a $\give[n]{}$ exponential.
Why is this the case?
In unbounded linear logic, this is necessary to preserve linearity---otherwise,
programs usable \emph{ad nauseam} could depend on linear resources. 
In bounded linear logic, it makes it possible to succinctly express the
\textsc{Store} rule, and separates reads from writes.
However, in \gtcp, we believe there is no good reason to keep this separation.

Given our description of $\give[n]{A}$ and $\take[n]{A}$ as vectors of pars and
tensors, one would expect that we have $\give[1]{A} \lequiv \take[1]{A}$.
For unit vectors, it should not matter whether we build them with tensors or
pars, as we will never have need for either! 
Therefore, we propose an alternative version of $\take[1]{}$ which simply drops
this restriction. 
\begin{proofblock}
  \AXC{$\seq[P]{ \Gamma , \tm[y]{A} }$}
  \SYM{\take[1]{}}
  \UIC{$\seq[x(y).P]{ \Gamma , \tm[x]{A} }$}
\end{proofblock}
When we add this rule, we conflate $\give[1]{A}$ and $\take[1]{A}$.
We could already derive $\take[1]{A} \limp \give[1]{A}$, but now we also have
the converse.
\begin{proofblock}
  \AXC{}
  \RightLabel{Ax}
  \UIC{$\seq[ \link{x}{y} ]{
      \tm[y]{A^\bot}, \tm[x]{A} }$}
  \RightLabel{\take[1]{}(2)}
  \UIC{$\seq[{ z(x).w(y).\link{x}{y} }]{
      \tm[w]{\take[1]{A^\bot}}, \tm[z]{\take[1]{A}} }$}
\end{proofblock}
This conflation leaves $\give[n]{A}$ and $\take[n]{A}$, for $n > 1$,
untouched.
We believe it to be a benign conflation, and will use it in the
remainder of this text whenever we mention $\take[1]{}$ or \gtcp.

\subsection{Conflating $\give[n]{A}$ and $\take[n]{A}$}
Give and take impose a strict structure on the kinds of non-deterministic which
we can model. Specifically, we always need one server process which offers to
communicate $n$ times, and $n$ independent client processes
There is a good reason for this---it ensures that after cut elimination, we are
left with a single, central process---the server process.
However, this may not always be what we desire.
Imagine a matchmaking service.
This could be a dating site, an online market place---any process whose purpose
it is to link \emph{two} pools of independent processes.
In such a scenario, it is entirely reasonable to write programs which end up as
several independent processes. For instance,
\[
  (x[u].P \mid x[v].Q \mid x(y).R \mid x(z).S)
\]
In the above program, the names in $P$, $Q$, $R$ and $S$ are disjoint, aside
from $x$. This means that whichever way we choose to communicate along $x$, we
will end up with two completely independent processes.
Logically, allowing such processes corresponds to adding the \textsc{Mix}-rule.
\begin{proofblock}
  \AXC{$\seq[P]{ \Gamma }$}
  \AXC{$\seq[Q]{ \Delta }$}
  \NOM{Mix}
  \BIC{$\seq[P \mid Q]{ \Gamma , \Delta }$}
\end{proofblock}
If we add \textsc{Mix} to our type system, we get proofs of $\bot \limp 1$ and
$A \mult B \limp A \parr B$. Vice versa, if we have a proof of $\bot \limp 1$,
we can derive \textsc{Mix}.
This phenomenon was recently investigated in the context of CP
by~\citet{atkey2016}. 
Unsurprisingly, due to the relation between $\give[n]{}/\take[n]{}$ and
$\parr/\mult$, \textsc{Mix} also gives us $\take[n]{A}\limp\give[n]{A}$. 
\begin{proofblock}
  \AXC{}
  \NOM{Ax}
  \UIC{$\seq{ A^\bot , A }$}
  \SYM{\give{}(2)}
  \UIC{$\seq{ \give[1]{A^\bot} , \give[1]{A} }$}
  \AXC{IH}
  \noLine
  \UIC{$\vphantom{()}{\smash[t]{\vdots}}$}
  \noLine
  \UIC{$\seq{ \give[n]{A^\bot} , \give[n]{A} }$}
  \NOM{Mix}
  \BIC{$\seq{
      \give[1]{A^\bot} , \give[1]{A} , \give[n]{A^\bot} , \give[n]{A} }$}
  \NOM{Cont(2)}
  \UIC{$\seq{ \give[n+1]{A^\bot} , \give[n+1]{A} }$}
\end{proofblock}
This relation holds the other way around as well---if we have a proof of
$\give[2]{1}$, we can derive \textsc{Mix}.

From \citet{atkey2016}, we also know that if we add \textsc{MultiCut}, we get
$1 \limp \bot$ and $A \parr B \limp A \mult B$ (and vice versa).
\begin{proofblock}
  \AXC{$\seq{ \Gamma , A_1^\bot , \ldots , A_n^\bot }$}
  \AXC{$\seq{ \Delta , A_1     , \ldots , A_n     }$}
  \NOM{MultiCut}
  \BIC{$\seq{ \Gamma , \Delta }$}
\end{proofblock}
Adding \textsc{MultiCut} also gives us $\give[n]{A}\limp\take[n]{A}$, see
\autoref{fig:conflate-give-and-take}, resulting in a proof of $\take[n]{A}
\lequiv \give[n]{A}$.
\begin{figure*}
  \begin{mdframed}
    \begin{proofblock}
      \AXC{}
      \NOM{Ax}
      \UIC{$\seq{ A^\bot , A }$}
      \SYM{\take[1]{}}
      \UIC{$\seq{ \take[1]{A^\bot} , A }$}
      \AXC{$\ldots$}
      \AXC{}
      \NOM{Ax}
      \UIC{$\seq{ A^\bot , A }$}
      \SYM{\take[1]{}}
      \UIC{$\seq{ \take[1]{A^\bot} , A }$}
      \NOM{Pool}
      \TIC{$\seq{ \take[n]{A^\bot} , A , \ldots , A }$}
      \AXC{}
      \NOM{Ax}
      \UIC{$\seq{ A^\bot , A }$}
      \SYM{\take[1]{}}
      \UIC{$\seq{ A^\bot , \take[1]{A} }$}
      \AXC{$\ldots$}
      \AXC{}
      \NOM{Ax}
      \UIC{$\seq{ A^\bot , A }$}
      \SYM{\take[1]{}}
      \UIC{$\seq{ A^\bot , \take[1]{A} }$}
      \NOM{Pool}
      \TIC{$\seq{ A^\bot , \ldots , A^\bot , \take[n]{A} }$}
      \NOM{MultiCut}
      \BIC{$\seq{ \take[n]{A^\bot} , \take[n]{A} }$}
      \SYM{\parr}
      \UIC{$\seq{ \give[n]{A} \limp \take[n]{A} }$}
    \end{proofblock}
  \end{mdframed}
  \caption{Conflation of $\give[n]{A}$ and $\take[n]{A}$ in the presence of
    \textsc{MultiCut}.}
  \label{fig:conflate-give-and-take}
\end{figure*}
The other way around, however, this relation does not hold.

We formulate a system in which we conflate $\give[n]{A}$ and $\take[n]{A}$,
following \citet{atkey2016} in calling this connective $\nod[n]{A}$---though,
since they provide no pronunciation other than ``an access point of type $A$'',
I will pronounce it as ``nod''.
We add a rule for $\nod[1]{}$ elimination, a contraction rule and the
\textsc{Mix} rule.
\begin{center}
  \begin{proofbox}
    \AXC{$\seq[P]{ \Gamma , \tm[y]{A} }$}
    \SYM{\nod{}}
    \UIC{$\seq[x\nod{y}.P]{ \Gamma , \tm[x]{\nod[1]{A}} }$}
  \end{proofbox}
  \begin{proofbox}
    \AXC{$\seq[P]{ \Gamma , \tm[y]{\nod[m]{A}} , \tm[z]{\nod[n]{A}} }$}
    \NOM{Contr.}
    \UIC{$\seq[\subst{P}{x}{y,z}]{ \Gamma , \tm[x]{\nod[m+n]{A}} }$}
  \end{proofbox}
\end{center}
There is no reason to add \textsc{Pool}, as it is derivable from \textsc{Contract}
and \textsc{Mix}.
\begin{proofblock}
  \AXC{$\seq{ \Gamma , \nod[m]{A} }$}
  \AXC{$\seq{ \Delta , \nod[n]{A} }$}
  \NOM{Mix}
  \BIC{$\seq{ \Gamma , \Delta , \nod[m]{A} , \nod[n]{A} }$}
  \NOM{Contract}
  \UIC{$\seq{ \Gamma , \Delta , \nod[m+n]{A} }$}
\end{proofblock}
We will refer to this system as \ndcp.

In \ndcp, we can derive a restricted version of \textsc{MultiCut}.
By applying \textsc{Cut} to a ``vector'' of $A$s, we can simulate communication
on multiple channels, as long as all of these channels have the same session
type.
\begin{proofblock}
  \AXC{$\seq{ \Gamma , A^\bot , \ldots , A^\bot  }$}
  \SYM{\nod{}}
  \UIC{$\seq{ \Gamma , \nod[1]{A^\bot} , \ldots , \nod[1]{A^\bot} }$}
  \NOM{Contr.}
  \UIC{$\seq{ \Gamma , \nod[n]{A^\bot} }$}
  \AXC{$\seq{ \Delta , A , \ldots , A }$}
  \SYM{\nod{}}
  \UIC{$\seq{ \Delta , \nod[1]{A} , \ldots , \nod[1]{A}     }$}
  \NOM{Contr.}
  \UIC{$\seq{ \Delta , \nod[n]{A} }$}
  \NOM{Cut}
  \BIC{$\seq{ \Gamma , \Delta }$}
\end{proofblock}
It is possible that cut elimination for \ndcp\ terminates.
The uses of \textsc{MultiCut} which lead to deadlocks invariably communicate on
two channels of dual types, as in
\begin{proofblock}
  \AXC{}
  \NOM{Ax}
  \UIC{$\seq[\link{x}{y}]{ \tm[x]{ A^\bot } , \tm[y]{ A } }$}
  \AXC{}
  \NOM{Ax}
  \UIC{$\seq[\link{y}{x}]{ \tm[y]{ A^\bot } , \tm[x]{ A } }$}
  \NOM{MultiCut}
  \BIC{$\seq[\nu x.\nu y.(\link{x}{y}\mid\link{y}{x})]{ }$}
\end{proofblock}
Why is \ndcp\ interesting?
It models an even more permissive form of non-determinism than
\gtcp+\textsc{Mix}.
In the latter, we can model a program in which two pools of processes are
non-deterministically linked together.
However, we cannot model a program in which two pools of sequentially
communicating processes are linked together. For instance,
\[
  (x[u_1].x[u_2].P \mid x[v].Q \mid x(w).R \mid x(z_1).x(z_2).S)
\]
We \emph{can} model such a process in \ndcp.
Why would we want to?
It may not unreasonable---in the case of a p\^{a}tisserie---to want to model a
customer buying \emph{two or more} pastries.
This would require us to have, on the one side, a process for the store which
communicates with $n$ customers sequentially.
On the other side, we would have a pool of processes which may communicate,
several times, with the store.
We could model this by having the store offer a transaction which can be used
some bounded number of times, e.g.\ %
\[
  \give[n]{( \coin\mult\cake^\bot )}
  \parr
  ( \forall{m \leq n}.{\give[m]{( \coin\mult\cake^\bot )}} ),
\]
but a simpler solution is to just require the customer to return to the pool
after the first transaction, and wait for another turn.

\subsection{Relation to recursion}
There is still an obvious open question.
In many of the proofs throughout this proposal, we've left open branches,
labeled IH for induction hypothesis.
However, as it stands we are unable to express these induction proofs
\emph{within} the languages \gtcp\ or \ndcp.
To do so, we would have to add some sort of induction principle.
For instance,
\begin{proofblock}
  \AXC{$\seq{
      \give[1]{\Gamma} , \take[1]{\Delta} }$}
  \AXC{$\seq{
      \forall{n} .
      \take[n]{\Gamma^\bot} , \give[n]{\Delta^\bot} ,
      \give[n+1]{\Gamma} , \take[n+1]{\Delta} }$}
  \NOM{Ind}
  \BIC{$\seq{
      \forall{n} .
      \give[n]{\Gamma^\bot} , \take[n]{\Delta} }$}
\end{proofblock}
\begin{proofblock}
  \AXC{$\seq{\forall{n} . \give[n]{\Gamma} , \take[n]{\Delta}}$}
  \SYM{\forall}
  \UIC{$\seq{\give[m]{\Gamma} , \take[m]{\Delta}}$}
\end{proofblock}
This would add a restricted form of induction and polymorphism over resource
variables to our language.

\citet{lindley2016} describe an extension of CP, called \mucp, which adds
connectives for structural recursion.
It would be interesting to see what the interactions are between these recursion
principles and induction on resource variables.

Using the above induction principle, we can unfold a $\give[n]{A}/\take[n]{A}$
into a stream or pars or tensors, i.e.\ %
\begin{gather*}
  \give[n]{A} \mult (\mu X.A \parr X) \limp (\mu X.A \parr X),\\
  \take[n]{A} \mult (\mu X.A \mult X) \limp (\mu X.A \mult X),
\end{gather*}
or fold the first $n$ values from a stream into a $\give[n]{A}/\take[n]{A}$,
\begin{gather*}
  (\nu X.A \parr X) \limp (\give[n]{A} \parr \nu X.A \parr X),\\
  (\nu X.A \mult X) \limp (\take[n]{A} \parr \nu X.A \mult X).
\end{gather*}
Equivalently, we can unfold a $\give[n]{A}/\take[n]{A}$ into a list,
\begin{gather*}
  \give[n]{A} \limp (\mu X. (A \parr X) \plus 1),\\
  \take[n]{A} \limp (\mu X. (A \mult X) \plus 1),
\end{gather*}
though, in order to unfold a list into a $\take[n]{A}$, we would need to add
existential quantification over resource variables.

We could these constructions in order to, for example, implement a ticket server
which sells $n$ tickets, labeled $1$ to $n$, by recursion.

It is not possible to encode  \textmu-recursion and \textnu-corecursion in terms
of the induction principle, as usage of the induction principle is always
bounded by a resource variable $n$.
The other way around is unsure, though unlikely, as there is no obvious way to
model the increasing resource index in the induction in a simply-typed setting.

\subsection{Formalization}
We plan to formalize the systems \gtcp\ and \ndcp\ using
Agda~\citep{norell2009}, and implement their cut elimination procedures. This
will give us a strong guarantee that the described cut elimination procedures
are correct and terminating. For this, we will use the techniques for separating
types and usages used in \citet{mcbride2016}. 

\section{Evaluation}
We can evaluate the success of this project by the success of \gtcp\ and \ndcp,
and the new kinds of non-deterministic programs which these systems will be able
to model.
Through its tight correspondence with bounded linear logic, it is likely 
that \gtcp\ will have a well-behaved cut elimination procedure.
This is less true for \ndcp, as their semantics closely resemble those of access
points, which are known to permit deadlocks and encodings of general recursion.
The formalization will play an important role in the evaluation of these
properties, as it will be able to give strong guarantees about the correctness
and termination properties of our systems.

It would be a bonus if we could find a way to unify the induction principle and
the principles for structural recursion, but this is unlikely unless we move to
a vastly more powerful system, e.g.\ dependent types.

\section{Research outputs}
By the end of this project, I hope to have produced the following outputs.
For \gtcp\ and \ndcp, I hope to have:
\begin{itemize}[noitemsep]
\item formulated the system;
\item given a cut elimination procedure;
\item given a proof of termination;
\item given a proof of deadlock freedom;
\item formalized the system; and
\item characterized the non-determinism.
\end{itemize}
In addition, I hope to have characterized the relation between the two systems,
both logically and with respect to non-determinism and concurrency.

\section{Workplan}
The outputs given in the previous section can be assigned to three distinct
categories: theory, evaluation, implementation.
The first four---all of which belong to theory---are all dependent on the
previous outputs. In addition, due to the similarity of the systems \gtcp\ and
\ndcp, the theoretical outputs for each system will be similar. For this reason,
I will work on \gtcp\ and \ndcp\ in parallel, at least until the formulation of
a cut elimination procedure, which is when I will have learned if \ndcp\ is a sane
logical system. 
Throughout the process, I will make an effort to formalize my results in Agda.

After we are satisfied that they are sane type systems, I will attempt to
characterize the non-determinism inherent in each system---with respect to each
other, local choice, and the \textpi-calculus in general.

Finally, I will write throughout, but will focus my effort more strongly on
writing in the last four months.
For a more detailed overview, see~\autoref{fig:workplan}.

\begin{figure*}
  \centering
  \newcommand{\months}[1]{\multicolumn{#1}{c}{\cellcolor{MidnightBlue}}}
  \begin{tabular}{lcccccccc}
    \hline
    & \multicolumn{8}{c}{2017} \\
    \hline
    & Jan & Feb & Mar & Apr & May & Jun & Jul & Aug \\
    \hline
    \textbf{Theory}         \\
    Formulate systems       &     \months{1} \\
    Prove cut elimination   &     \months{3} \\
    Prove termination       &&&   \months{2} \\
    Prove deadlock freedom  &&&&  \months{2} \\
    \textbf{Implementation} \\
    Formalization in Agda   &     \months{6} \\
    \textbf{Evaluation}     \\
    Characterize N.D.       &&&&  \months{4} \\
    \textbf{Writeup}        \\
    Write report            &&&&& \months{4}
  \end{tabular}
  \caption{My workplan.}
  \label{fig:workplan}
\end{figure*}

\bibliographystyle{apalike}
\bibliography{main}

\end{document}
